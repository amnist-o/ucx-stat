---
title: "Logistic Regression"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assessment
There are five different chasers in “The Chase” show.

Fit individual binary logistic regression models showing how the chance of winning depends on the Team Score when the Chaser is Shaun, and when the Chaser is Paul.
- Interpret the results.
- Plot the estimated probability curves.
- Evaluate the Apparent Error Rates (AERs)
- Who do you think is the better Chaser?

```{r packages, message=FALSE}
library(tidyverse)
```

```{r load data}
chase <- read_lines(file = "datasets/chase")
df <- read.table(file = chase, header = T, sep = ",",stringsAsFactors = T)
summary(df)
```

Fit *individual* models based on chaser: Paul and Shaun.

```{r models}
mp <- glm(Win ~ TeamScore,
          data = df,subset = Chaser=="Paul",
          family = "binomial"(link = "logit"))
ms <- update(mp,subset= Chaser=="Shaun")
```

Let's see how the TeamScore affect the chance of winning from each model.  
When Paul is the chaser:

```{r paul}
summary(mp)
```

When Shaun is the chaser:

```{r shaun}
summary(ms)
```

From the results, we can see that team score has more positive impact to the odds of winning when the chaser is Paul. 1 unit increased in team score increase the log odds of winning by `r coef(mp)[2]` or increase in odds ratio of `r exp(coef(mp)[2])` when the chaser is Paul. While the same score increased only increase the log odds of winning by `r coef(ms)[2]` and increase the odds ratio of `r exp(coef(ms)[2])` when the chaser is Shaun.

Next, we plot the estimated probability curves.
```{r estimated plot}
plot(df$TeamScore[df$Chaser%in%c("Paul","Shaun")],
     jitter(df$Win[df$Chaser%in%c("Paul","Shaun")]),
     xlab='Team Score',ylab='Probability of Winning',yaxt='n',
     xlim = c(0,28))
abline(h=0,col='gray');abline(h=1,col='gray')
axis(2,at=0:1,c('Lose','Win'))
# add logit curve
curve(1/(1+exp(-(mp$coef[1]+mp$coef[2]*x))),col='peru',lwd=2,add=T)
curve(1/(1+exp(-(ms$coef[1]+ms$coef[2]*x))),col='salmon',lwd=2,add=T)
# add legend
legend(x=1,y=1,
       legend=c("Paul","Shaun"),
       col = c("peru","salmon"),
       lty=1,lwd=2)
```

Let's check the performance of our model with AERs.
```{r aer}
aer <- function(model){
  stopifnot("glm"%in%class(model))
  cbind(model$model,estimates = round(model$fitted.values)) -> x
  table(x[,1],x$estimate,dnn = list("Actual","Predicted")) -> tab
  return(list("AER table" = tab,
              "Correct ratio" = sum(diag(tab))/sum(tab)))
}
cat("Chaser: Paul\n")
aer(mp)
cat("Chaser: Shaun\n")
aer(ms)
```

Who is the better chaser? Based on the probability of winning, Paul is the better chaser. However let's check the model with chaser as a categorical variable:
```{r modelc}
m <- update(mp,.~.+Chaser,subset = Chaser %in% c("Paul","Shaun"))
summary(m)
```

Paul is the better chaser since chaser Shaun increase the log odds of winning by `r coef(m)[3]`.